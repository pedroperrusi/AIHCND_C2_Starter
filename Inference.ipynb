{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "\n",
    "##Import any other stats/DL/ML packages you may need here. E.g. Keras, scikit-learn, etc.\n",
    "from cv2 import cv2\n",
    "\n",
    "import skimage\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "def check_dicom(filenames):\n",
    "    dicom_data = []\n",
    "    for img_name in filenames:\n",
    "        print('Load file {} ...'.format(img_name))\n",
    "        dcm = pydicom.dcmread(img_name)\n",
    "        fields = [dcm.PatientID, int(dcm.PatientAge), dcm.PatientSex, dcm.Modality, dcm.StudyDescription, dcm.Rows, dcm.Columns, img_name, dcm.pixel_array]\n",
    "        dicom_data.append(fields)\n",
    "    dicom_df = pd.DataFrame(dicom_data, columns = ['PatientID','PatientAge','PatientSex','Modality','Finding Labels','Rows','Columns', 'Filename', 'Image'])\n",
    "    print(dicom_df)\n",
    "    return dicom_df\n",
    "    \n",
    "    \n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "\n",
    "def clahe_scaling(image):\n",
    "        clahe = cv2.createCLAHE(clipLimit=3, tileGridSize=(16, 16))\n",
    "        return clahe.apply(image)\n",
    "\n",
    "def preprocess_image(src, IMG_SIZE=(224,224), INPUT_SHAPE=(1, 224,224,3)):\n",
    "#     '''Takes an input image and returns a modified version of it'''\n",
    "    dst = cv2.resize(src, IMG_SIZE) / 255\n",
    "    dst = skimage.img_as_ubyte(dst)\n",
    "    dst = clahe_scaling(dst)\n",
    "    dst = skimage.img_as_float(dst)\n",
    "    dst = cv2.cvtColor(dst.astype('float32'), cv2.COLOR_GRAY2RGB ) * 255\n",
    "    return np.broadcast_to(dst, INPUT_SHAPE)\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path, weight_path):\n",
    "    # load model\n",
    "    model = tensorflow.keras.models.load_model(model_path)\n",
    "    model.load_weights(weight_path)\n",
    "    # summarize model.\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    prediction = model.predict(img, verbose = True)\n",
    "    return prediction < thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 17:06:52.873096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 17:06:52.897133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 17:06:52.898062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 17:06:52.900026: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-10 17:06:52.901347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 17:06:52.902266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 17:06:52.903075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 17:06:53.232478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 17:06:53.232697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 17:06:53.232871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 17:06:53.233041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2714 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "VGG16_preprocessing (Sequent (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 21,137,729\n",
      "Trainable params: 19,402,241\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "my_model = load_model(model_path='my_model.h5', weight_path='fine_tunning.best.hdf5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking DICOM test files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file test1.dcm ...\n",
      "Load file test2.dcm ...\n",
      "Load file test3.dcm ...\n",
      "Load file test4.dcm ...\n",
      "Load file test5.dcm ...\n",
      "Load file test6.dcm ...\n",
      "  PatientID  PatientAge PatientSex Modality Finding Labels  Rows  Columns  \\\n",
      "0         2          81          M       DX     No Finding  1024     1024   \n",
      "1         1          58          M       DX   Cardiomegaly  1024     1024   \n",
      "2        61          77          M       DX       Effusion  1024     1024   \n",
      "3         2          81          M       DX     No Finding  1024     1024   \n",
      "4         2          81          M       CT     No Finding  1024     1024   \n",
      "5         2          81          M       DX     No Finding  1024     1024   \n",
      "\n",
      "    Filename                                              Image  \n",
      "0  test1.dcm  [[199, 175, 152, 133, 124, 118, 113, 111, 110,...  \n",
      "1  test2.dcm  [[202, 199, 195, 193, 195, 194, 193, 192, 184,...  \n",
      "2  test3.dcm  [[142, 142, 143, 141, 143, 140, 140, 136, 137,...  \n",
      "3  test4.dcm  [[199, 175, 152, 133, 124, 118, 113, 111, 110,...  \n",
      "4  test5.dcm  [[199, 175, 152, 133, 124, 118, 113, 111, 110,...  \n",
      "5  test6.dcm  [[199, 175, 152, 133, 124, 118, 113, 111, 110,...  \n"
     ]
    }
   ],
   "source": [
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "dicom_df = check_dicom(test_dicoms)\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE=(1,224,224,3) # This might be different if you did not use vgg16\n",
    "\n",
    "# - ImgNet mean subtraction preprocessing is already into the model\n",
    "# img_mean = # loads the mean image value they used during training preprocessing\n",
    "# img_std = # loads the std dev image value they used during training preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing Predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "thresh = 0.24\n",
    "\n",
    "# use the .dcm files to test your prediction\n",
    "for index, img_data in dicom_df.iterrows():\n",
    "    img = img_data['Image']\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "        \n",
    "    img_proc = preprocess_image(img)\n",
    "    pred = predict_image(my_model,img_proc,thresh)\n",
    "    print(f'Predicted: {pred}, findings: {img_data[\"Finding Labels\"]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 17:06:53.832133: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-10 17:06:54.162729: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n",
      "2021-11-10 17:06:54.339616: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Predicted: [[False]], findings: No Finding\n",
      "1/1 [==============================] - 0s 11ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Predicted: [[ True]], findings: Cardiomegaly\n",
      "1/1 [==============================] - 0s 11ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Predicted: [[False]], findings: Effusion\n",
      "1/1 [==============================] - 0s 10ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Predicted: [[False]], findings: No Finding\n",
      "1/1 [==============================] - 0s 11ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Predicted: [[False]], findings: No Finding\n",
      "1/1 [==============================] - 0s 11ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Predicted: [[False]], findings: No Finding\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}